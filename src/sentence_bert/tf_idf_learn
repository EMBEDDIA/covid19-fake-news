#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Nov 12 15:30:04 2020

@author: bosko
"""

import config
import os
import glob
import json
from tqdm import tqdm
from eval import eval
from lemmagen3 import Lemmatizer
from sklearn import cluster
from gensim.test.utils import common_texts, get_tmpfile
from gensim.models import Word2Vec
from gensim.models import KeyedVectors
import matplotlib.pyplot as plt
from sklearn import cluster
from gensim.test.utils import datapath
import string
import pandas as pd 
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer 
import random
import re
import pickle
from stopwordsiso import stopwords

from tf_idf_solve import predict, prepare, extract_naive

def build_kw(path, lang='et'):
    outs = {}
    sw = stopwords(lang)
    with open(path,'r',encoding='utf-8') as f:
        for line in f:
            line = line.strip("\n")
            parsed = prepare(line)        
            if not parsed in sw:
                outs[parsed] = outs.get(parsed,[]) + [line]
    return outs


def load(lang='et'):
    tf_idf = pickle.load(open("tf_idf_"+lang+".pkl", "rb"))
    keywords_o = pickle.load(open("keywords_"+lang+".pkl", "rb"))
    return keywords_o, tf_idf    

def save(keyword, tf_idf, lang='et'):
    with open(os.path.join(config.PICKLES, "keywords_"+lang+".pkl"), "wb") as f:
        pickle.dump(keyword, f)
    with open(os.path.join(config.PICKLES, "tf_idf_"+lang+".pkl"), "wb") as f:
        pickle.dump(tf_idf, f)


tqdm.pandas()
def parse_tags(file="predictions/russian_predictions.csv"):
    data = pd.read_csv(file, encoding='utf-8') 
    data = data.fillna(" ")
    print("data_prepare")
    #print("OK")
    dats = []
    abstracts = data["abstract"] + " " + data["title"]
    dats = abstracts.progress_apply(prepare) #map(lambda txt: prepare(txt))
  
    data = {
        "text+title" : abstracts,
        "processed" : dats.values,
        "original_tags": data["keywords_in_text"].to_list(), 
        "tnt_tags": data["predicted"].to_list(),
        }        
    return data

def learn(prediction_path = "predictions/russian_predictions.csv", tags_path = "tags/Ekspress_tagid-cyrl..csv", lang="ru"):
    #Data
    data = parse_tags(prediction_path)
    #Taglists
    taglist = build_kw("tags/Ekspress_tagid-latin.csv" if lang == 'et' else "tags/Ekspress_tagid-cyrl.csv", lang= lang)
    outs = taglist
    tfidf_vectorizer=TfidfVectorizer(use_idf=True, vocabulary = list(outs.keys()), ngram_range = (1,2))
    _ = tfidf_vectorizer.fit_transform(data["processed"])   
    #export
    save(outs,tfidf_vectorizer, lang)    
    
    #predict
    data["tfidf_tags"] =  data["text+title"].map(lambda txt: predict(txt, lang))    
    data["naive_tags"] = data["naive"].progress_apply(extract_naive) #.map(lambda txt: extract_naive(txt))
    
    #["text+title","original_tags","tnt_tags","tfidf_tags","naive_tags"]
    del data["processed"]
    #export
    path_new_predictions = os.path.join("predictions","estonian_ru.csv")
    data.to_csv(path_new_predictions, index=False, header=False)
    
    print(data)
